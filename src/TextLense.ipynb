{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43406af-74f8-4c0f-810c-872ed5ac4f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:53:06.104213Z",
     "iopub.status.busy": "2025-05-18T23:53:06.102842Z",
     "iopub.status.idle": "2025-05-18T23:53:08.683536Z",
     "shell.execute_reply": "2025-05-18T23:53:08.683293Z",
     "shell.execute_reply.started": "2025-05-18T23:53:06.104159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from main_notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ecf4cc4-e60c-4b99-9158-6a14f6c8c756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:55:30.817021Z",
     "iopub.status.busy": "2025-05-18T23:55:30.816707Z",
     "iopub.status.idle": "2025-05-18T23:55:30.821568Z",
     "shell.execute_reply": "2025-05-18T23:55:30.820551Z",
     "shell.execute_reply.started": "2025-05-18T23:55:30.816998Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9696e05a-fd56-452d-a058-9f0202cd65aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:55:32.267673Z",
     "iopub.status.busy": "2025-05-18T23:55:32.267013Z",
     "iopub.status.idle": "2025-05-18T23:55:32.720763Z",
     "shell.execute_reply": "2025-05-18T23:55:32.720430Z",
     "shell.execute_reply.started": "2025-05-18T23:55:32.267632Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Initialize sentiment analysis pipeline\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae86ee6-809e-461f-84ec-25c2e91818ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:55:33.894128Z",
     "iopub.status.busy": "2025-05-18T23:55:33.893148Z",
     "iopub.status.idle": "2025-05-18T23:55:35.754076Z",
     "shell.execute_reply": "2025-05-18T23:55:35.753711Z",
     "shell.execute_reply.started": "2025-05-18T23:55:33.894073Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize zero-shot classification pipeline\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "969ca2dc-2d9e-4d8e-842a-81bb03778ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:55:37.353304Z",
     "iopub.status.busy": "2025-05-18T23:55:37.352788Z",
     "iopub.status.idle": "2025-05-18T23:55:37.901225Z",
     "shell.execute_reply": "2025-05-18T23:55:37.900865Z",
     "shell.execute_reply.started": "2025-05-18T23:55:37.353265Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize emotion classification pipeline\n",
    "emotion_model_name = \"SamLowe/roberta-base-go_emotions\"\n",
    "emotion_tokenizer = AutoTokenizer.from_pretrained(emotion_model_name)\n",
    "emotion_model = AutoModelForSequenceClassification.from_pretrained(emotion_model_name)\n",
    "emotion_classifier = pipeline(\"text-classification\", model=emotion_model, tokenizer=emotion_tokenizer, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7aebe41-e8e0-4437-a4fd-07ca7e13ecea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:55:41.153306Z",
     "iopub.status.busy": "2025-05-18T23:55:41.152693Z",
     "iopub.status.idle": "2025-05-18T23:55:41.173185Z",
     "shell.execute_reply": "2025-05-18T23:55:41.172615Z",
     "shell.execute_reply.started": "2025-05-18T23:55:41.153269Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_text(questions_data, total_reviews, progress_callback=None, status_callback=None):\n",
    "    \"\"\"\n",
    "    Analyzes text reviews for sentiment, performs zero-shot classification, and detects emotions\n",
    "    based on provided questions and categories.\n",
    "\n",
    "    Args:\n",
    "        questions_data (list): A list of dictionaries, each containing:\n",
    "            - 'question' (str): The classification question.\n",
    "            - 'reviews' (list): A list of text strings (reviews) for this question.\n",
    "            - 'categories' (list): A list of category strings for the question.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the original reviews,\n",
    "                          sentiment analysis results, and zero-shot classification results\n",
    "                          for each question.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    processed_reviews_count = 0\n",
    "\n",
    "    for q_data in questions_data:\n",
    "        question = q_data['question']\n",
    "        reviews = q_data['reviews']\n",
    "        categories = q_data['categories']\n",
    "\n",
    "        if not question or not reviews or not categories:\n",
    "            # Skip if essential data is missing for this question\n",
    "            continue\n",
    "\n",
    "        if status_callback:\n",
    "            status_callback(f\"Analyzing question: {question}\")\n",
    "\n",
    "        for review_data in reviews:\n",
    "            review = review_data['review']\n",
    "            source = review_data['source'] # Extract source\n",
    "\n",
    "            if status_callback:\n",
    "                status_callback(f\"Analyzing review from '{source}': {review[:50]}...\") # Show first 50 chars of review and source\n",
    "\n",
    "            # Perform sentiment analysis with truncation\n",
    "            sentiment_result = sentiment_task(review, max_length=512, truncation=True)[0]\n",
    "            sentiment_label = sentiment_result['label']\n",
    "            sentiment_score = sentiment_result['score']\n",
    "\n",
    "            # Perform emotion classification with truncation\n",
    "            emotion_result = emotion_classifier(review, max_length=512, truncation=True)[0]\n",
    "            emotion_label = emotion_result[0]['label']\n",
    "\n",
    "            # Perform zero-shot classification with truncation\n",
    "            classification_result = classifier(review, categories, multi_label=True, max_length=512, truncation=True)\n",
    "            classification_labels = classification_result['labels']\n",
    "            classification_scores = classification_result['scores']\n",
    "\n",
    "            result_entry = {\n",
    "                \"question\": question,\n",
    "                \"review\": review,\n",
    "                \"source\": source, # Include source in result_entry\n",
    "                \"sentiment_label\": sentiment_label,\n",
    "                \"sentiment_score\": sentiment_score,\n",
    "                \"emotion_label\": emotion_label,\n",
    "            }\n",
    "\n",
    "            # Add classification results dynamically based on categories\n",
    "            for i, label in enumerate(classification_labels):\n",
    "                 result_entry[f\"classification_{label}_score\"] = classification_scores[i]\n",
    "\n",
    "            # Add the top predicted label as a separate column for easier analysis\n",
    "            if classification_labels:\n",
    "                 result_entry[f\"classification_top_label\"] = classification_labels[0]\n",
    "                 result_entry[f\"classification_top_score\"] = classification_scores[0]\n",
    "            else:\n",
    "                 result_entry[f\"classification_top_label\"] = None\n",
    "                 result_entry[f\"classification_top_score\"] = None\n",
    "\n",
    "\n",
    "            all_results.append(result_entry)\n",
    "\n",
    "            # Update progress bar\n",
    "            processed_reviews_count += 1\n",
    "            if progress_callback:\n",
    "                progress_callback(processed_reviews_count / total_reviews)\n",
    "\n",
    "    print(f\"Content of all_results before DataFrame conversion: {all_results}\")\n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "def visualize_results(results_df):\n",
    "    \"\"\"\n",
    "    Visualizes the analysis results using Streamlit.\n",
    "\n",
    "    Args:\n",
    "        results_df (pandas.DataFrame): DataFrame containing the analysis results.\n",
    "    \"\"\"\n",
    "    # This function is intended for Streamlit, but keeping it here for potential use\n",
    "    # in a notebook with Streamlit components or for clarity of the original structure.\n",
    "    # In a pure notebook, you would likely use other plotting libraries like matplotlib or seaborn.\n",
    "    import streamlit as st\n",
    "    import plotly.express as px\n",
    "    import altair as alt\n",
    "\n",
    "    st.subheader(\"Analysis Results Visualization\")\n",
    "\n",
    "    if results_df.empty:\n",
    "        st.info(\"No results to visualize.\")\n",
    "        return\n",
    "\n",
    "    # Sentiment Distribution by Source (Donut Charts)\n",
    "    st.write(\"### Sentiment Distribution by Source\")\n",
    "    if 'source' in results_df.columns:\n",
    "        for source in results_df['source'].unique():\n",
    "            st.write(f\"#### Source: {source}\")\n",
    "            source_df = results_df[results_df['source'] == source]\n",
    "            sentiment_counts = source_df['sentiment_label'].value_counts().reset_index()\n",
    "            sentiment_counts.columns = ['sentiment_label', 'count']\n",
    "\n",
    "            # Define custom colors\n",
    "            color_map = {'positive': '#7b94a6', 'negative': '#a25450', 'neutral': '#edeadc'}\n",
    "\n",
    "            fig = px.pie(sentiment_counts, values='count', names='sentiment_label',\n",
    "                         title=f'Sentiment Distribution for {source}',\n",
    "                         hole=0.5, # Creates the donut shape\n",
    "                         color='sentiment_label',\n",
    "                         color_discrete_map=color_map) # Apply custom colors\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"Source information not available for sentiment visualization.\")\n",
    "\n",
    "\n",
    "    # Emotion Distribution by Source (Bar Charts)\n",
    "    st.write(\"### Emotion Distribution by Source\")\n",
    "    if 'source' in results_df.columns:\n",
    "        for source in results_df['source'].unique():\n",
    "            st.write(f\"#### Source: {source}\")\n",
    "            source_df = results_df[results_df['source'] == source]\n",
    "            emotion_counts = source_df['emotion_label'].value_counts().reset_index()\n",
    "            emotion_counts.columns = ['emotion_label', 'count']\n",
    "            chart = alt.Chart(emotion_counts).mark_bar(color='#ca8f56').encode(\n",
    "                x=alt.X('count:Q', title='Count'),\n",
    "                y=alt.Y('emotion_label:N', title='Emotion')\n",
    "            ).properties(\n",
    "                title=f'Emotion Distribution for {source}'\n",
    "            )\n",
    "            st.altair_chart(chart, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"Source information not available for emotion visualization.\")\n",
    "\n",
    "\n",
    "    # Top Classification Label Distribution per Question (Bar Charts - unchanged)\n",
    "    st.write(\"### Top Classification Label Distribution per Question\")\n",
    "    for question in results_df['question'].unique():\n",
    "        st.write(f\"#### Question: {question}\")\n",
    "        question_df = results_df[results_df['question'] == question]\n",
    "        if 'classification_top_label' in question_df.columns:\n",
    "            classification_counts = question_df['classification_top_label'].value_counts().reset_index()\n",
    "            classification_counts.columns = ['classification_top_label', 'count']\n",
    "            chart = alt.Chart(classification_counts).mark_bar(color='#1d2d3d').encode(\n",
    "                x=alt.X('count:Q', title='Count'),\n",
    "                y=alt.Y('classification_top_label:N', title='Classification Label')\n",
    "            ).properties(\n",
    "                title=f'Top Classification Label Distribution for {question}'\n",
    "            )\n",
    "            st.altair_chart(chart, use_container_width=True)\n",
    "        else:\n",
    "            st.info(\"No classification results for this question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40f20990-3fd7-4861-a58d-1657a21a04fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:56:41.037964Z",
     "iopub.status.busy": "2025-05-18T23:56:41.037163Z",
     "iopub.status.idle": "2025-05-18T23:56:41.047465Z",
     "shell.execute_reply": "2025-05-18T23:56:41.046226Z",
     "shell.execute_reply.started": "2025-05-18T23:56:41.037921Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/gp_surgery_reviews_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7954f42-6826-465e-82ac-ca4895c5bd06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T23:56:47.298464Z",
     "iopub.status.busy": "2025-05-18T23:56:47.297813Z",
     "iopub.status.idle": "2025-05-18T23:56:47.318951Z",
     "shell.execute_reply": "2025-05-18T23:56:47.318165Z",
     "shell.execute_reply.started": "2025-05-18T23:56:47.298420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1 - Describe your experience accessing Enhanced Access Services</th>\n",
       "      <th>Q2 - Describe your experience in dealing with Enhanced Access staff</th>\n",
       "      <th>Q3 - Describe your experience in talking to us on the phone</th>\n",
       "      <th>Q4 - Describe your experience accessing Enhanced Access Services</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was able to speak to the pharmacist the day ...</td>\n",
       "      <td>The reception staff were friendly but slow. \\n...</td>\n",
       "      <td>The service always remains helpful and very fr...</td>\n",
       "      <td>I was able to speak to the pharmacist the day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The reception staff were friendly but disorgan...</td>\n",
       "      <td>I am in a difficult position I have from my an...</td>\n",
       "      <td>The phone system is STILL random you often hav...</td>\n",
       "      <td>The reception staff were friendly but disorgan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Despite the long wait, the staff were friendl...</td>\n",
       "      <td>Reception staff were friendly and welcoming bu...</td>\n",
       "      <td>The staff were friendly and welcoming but the ...</td>\n",
       "      <td>\"Despite the long wait, the staff were friendl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The waiting room was surprisingly quiet and co...</td>\n",
       "      <td>The doctors and nurses were extremely helpful ...</td>\n",
       "      <td>The staff were very helpful and friendly but t...</td>\n",
       "      <td>The waiting room was surprisingly quiet and co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Q1 - Describe your experience accessing Enhanced Access Services  \\\n",
       "0  I was able to speak to the pharmacist the day ...                 \n",
       "1  The reception staff were friendly but disorgan...                 \n",
       "2  \"Despite the long wait, the staff were friendl...                 \n",
       "3  The waiting room was surprisingly quiet and co...                 \n",
       "\n",
       "  Q2 - Describe your experience in dealing with Enhanced Access staff  \\\n",
       "0  The reception staff were friendly but slow. \\n...                    \n",
       "1  I am in a difficult position I have from my an...                    \n",
       "2  Reception staff were friendly and welcoming bu...                    \n",
       "3  The doctors and nurses were extremely helpful ...                    \n",
       "\n",
       "  Q3 - Describe your experience in talking to us on the phone  \\\n",
       "0  The service always remains helpful and very fr...            \n",
       "1  The phone system is STILL random you often hav...            \n",
       "2  The staff were friendly and welcoming but the ...            \n",
       "3  The staff were very helpful and friendly but t...            \n",
       "\n",
       "  Q4 - Describe your experience accessing Enhanced Access Services  \n",
       "0  I was able to speak to the pharmacist the day ...                \n",
       "1  The reception staff were friendly but disorgan...                \n",
       "2  \"Despite the long wait, the staff were friendl...                \n",
       "3  The waiting room was surprisingly quiet and co...                "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0861d-4811-4c47-a02c-1908e1b806d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
